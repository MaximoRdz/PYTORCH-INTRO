{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67a4215e",
   "metadata": {},
   "source": [
    "# Lesson 1: Tensors\n",
    "**Pytorch:** Optimized tensor library for deep learning using GPUs and CPUs.\n",
    "The basic building block of PyTorch is the torch.tensor (similar to a numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59b999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407fcdcb",
   "metadata": {},
   "source": [
    "## Comparison of Numpy and PyTorch\n",
    "Arrays are created in the same fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54a4608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.linspace(0, 1, 5)\n",
    "t = torch.linspace(0, 1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc600434",
   "metadata": {},
   "source": [
    "They can be resized in similar ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecdee1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.arange(0, 9)\n",
    "n.reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27618cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(0, 9)\n",
    "t.reshape(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c7bb0",
   "metadata": {},
   "source": [
    "## General broadcasting rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f746b39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(1, 5, 10)\n",
    "y = np.arange(0, 10)\n",
    "x == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ece78b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 30])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2, 3])\n",
    "b = np.array([5, 10])\n",
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a614c66",
   "metadata": {},
   "source": [
    "**Rules for higher dimensions**\n",
    "\n",
    "When the dimensions aren't the same it gets a bit more complicated.\\\n",
    "When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimensions and works its way left. Two dimensions are compatible when, \n",
    "* 1. they are equal, or\n",
    "* 2. one of them is 1\n",
    "\n",
    "In order to apply these rules we check the shape of the arrays (a.shape)\n",
    "\n",
    "Shape 1: (1, 3)\n",
    "Shape 2: (5, 3)\n",
    "\n",
    "In this case we can clearly see that the rules hold so they are compatible and we could operate (addition, multiplication, ...) as we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2ce2955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((6, 5))\n",
    "print(a.shape)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a701ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(5).reshape((1, 5))\n",
    "print(b.shape)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c047b",
   "metadata": {},
   "source": [
    "According to the rules they are compatible and if we perform a+b we expect the element-wise summation of the b array to every row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12d4330d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcca5636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.ones((5, 6))\n",
    "print(c.shape)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4ac5175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.arange(5).reshape((5, 1))\n",
    "print(d.shape)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1234dee",
   "metadata": {},
   "source": [
    "In this case the dimensions are switched so we expect it to sum d to every column of c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2a14aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1.],\n",
       "       [2., 2., 2., 2., 2., 2.],\n",
       "       [3., 3., 3., 3., 3., 3.],\n",
       "       [4., 4., 4., 4., 4., 4.],\n",
       "       [5., 5., 5., 5., 5., 5.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c + d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef384f9",
   "metadata": {},
   "source": [
    "**The same rules apply to PyTorhc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfac864d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at = torch.ones((6, 5))\n",
    "print(at.shape)\n",
    "at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e7874f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt = torch.arange(5).reshape((1, 5))\n",
    "print(bt.shape)\n",
    "bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2afbe42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at + bt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebe0114",
   "metadata": {},
   "source": [
    "### What if we don't have the same number of dimensions?\n",
    "\n",
    "In the examples above we had two dims per array/tensor:\\\n",
    "(5, 6) and (5, 1)\\\n",
    "But this is not a condition for broadcasting to be possible\n",
    "\n",
    "Image  (3d array): 256 x 256 x 3\\\n",
    "Scale  (1d array):             3\\\n",
    "Result (3d array): 256 x 256 x 3\n",
    "\n",
    "If so, python will automatically fill the 'missing' dimension with 1 and the rules will apply as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54ec34f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 1.5000, 1.0000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = torch.tensor([0.5, 1.5, 1]) # RGB format\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "850fbe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.rand((256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ae39d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = image * scale\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e582d",
   "metadata": {},
   "source": [
    "the result is also an image with the appropiate dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf9e6c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1264, 0.0715, 0.7159])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad92ffec",
   "metadata": {},
   "source": [
    "and if we check for example the first element we can see that the scale factor have worked as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20566446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0632, 0.1072, 0.7159])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b1d56f",
   "metadata": {},
   "source": [
    "**Example of an array with 2 images**\n",
    "\n",
    "Image  (4d array): 2 x 256 x 256 x 3\\\n",
    "Scale  (4d array): 2 x 1 x 1 x 3\\\n",
    "Result (3d array): 2 x 256 x 256 x 3\n",
    "\n",
    "Now we want to apply a different filter to each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1f0125ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 1.0000, 1.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.5000, 0.5000, 0.5000]]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.rand((2, 256, 256, 3))\n",
    "scale = torch.tensor([1, 1, 1, 0.5, 0.5, 0.5]).reshape(2, 1, 1, 3)\n",
    "scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414869cc",
   "metadata": {},
   "source": [
    "as we can see we are leaving the first image untouched and scaling by 0.5 every color (RGB) of the second one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc84d46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 256, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = image * scale\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55a6390f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1902, 0.6314, 0.5439])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first pixel of the first image\n",
    "image[0,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6df6b1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5144, 0.5427, 0.7108])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first pixel of the second image\n",
    "image[1,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5116f1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1902, 0.6314, 0.5439])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0,0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414d42a3",
   "metadata": {},
   "source": [
    "as we wanted the first image remains unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "100e1e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2572, 0.2714, 0.3554])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1,0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993fada2",
   "metadata": {},
   "source": [
    "while the second image is scaled by 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc6285d",
   "metadata": {},
   "source": [
    "### Operations across dimensions \n",
    "Obviusly, basic operations can be done as usual in one 1dim tensor,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27bae14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.1250), tensor(1.6520), tensor(4.), tensor(0.5000))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([0.5,1,3,4])\n",
    "t.mean(), t.std(), t.max(), t.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153308fc",
   "metadata": {},
   "source": [
    "But suppose we have a 2d tensor and want to compute the mean value of the columns\n",
    "\n",
    "**Note:** Taking the mean of each column meanstaking the mean **across the rows** which are the first dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d43ffef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.],\n",
       "        [16., 17., 18., 19.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(20, dtype = float).reshape(5, 4)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0171909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.,  9., 10., 11.], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean across the rows\n",
    "torch.mean(t, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76507128",
   "metadata": {},
   "source": [
    "For arrays of higher dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75f5d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(5, 256, 256, 3) # five images\n",
    "# shape = image x rows x columns x RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd87e3d",
   "metadata": {},
   "source": [
    "* Mean across the batch (number of images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35f82ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(t, axis = 0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f611e92f",
   "metadata": {},
   "source": [
    "* Mean across the color channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3554019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(t, axis = -1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda142c7",
   "metadata": {},
   "source": [
    "* Taking only the **maximum** color channel value:\\\n",
    "Commonly use in image segmentation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d206fa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, indices = torch.max(t, axis = -1)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14c2f7",
   "metadata": {},
   "source": [
    "### Where do PyTorch and NumPy differ?\n",
    "\n",
    "The main advantage of PyTorch is its capacity to automatically compute gradients of operations, for example\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "y = \\sum_i x^{3}_i\n",
    "\\end{equation}\n",
    "$$\n",
    "has a gradient\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial y}{\\partial x_i} = 3 x^{2}_i\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "488dba28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 8.],\n",
       "        [4., 6.]], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[5., 8.], [4., 6.]], requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8c8fa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(917., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.pow(3).sum()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c86cc81",
   "metadata": {},
   "source": [
    "Compute the gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ea5b386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 75., 192.],\n",
       "        [ 48., 108.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward() # method of torch tensors\n",
    "x.grad # the gradient is store in the initial tensor object and can be access as here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ebca10",
   "metadata": {},
   "source": [
    "Double check with the analytical formula: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f311a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 75., 192.],\n",
       "        [ 48., 108.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * x * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db7e89",
   "metadata": {},
   "source": [
    "### Additional benefits\n",
    "\n",
    "Any sort of large matrix multiplication problem is faster with torch tensors than it is with numpy, especially if you are running on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d194c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003537200012942776\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn((1000, 1000))\n",
    "B = torch.randn((1000, 1000))\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "torch.matmul(A, B)\n",
    "t2 = time.perf_counter()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4908906b",
   "metadata": {},
   "source": [
    "Using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c07e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randn(int(1e4)).reshape(100, 100)\n",
    "B = np.random.randn(int(1e4)).reshape(100, 100)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "A@B\n",
    "t2 = time.perf_counter()\n",
    "print(t2-t1)\n",
    "\n",
    "# THE KERNEL DIES IF YOU RUN THIS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
